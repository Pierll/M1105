<!DOCTYPE html>
<html lang="fr">
<head>
	<meta charset="UTF-8">
	
	<title>Machine Learning</title>

	<link rel="stylesheet" type="text/css" href="css/style.css">

</head>
<body>

<!-- NAV BAR -->
<nav>
	<div class="logo">
		<a href="index.html">
         <img class="img" alt="logo du site" src="img/Logo.png">
      	</a>
	</div>
	<div class="pageTitle">
		<h1 class="pageTitle-text">Machine Learning</h1>
	</div>
	<div class="nav_right">
		<a href="index.html"> Accueil</a>
		<a href="page1.html"> Alpha GO </a>
		<a class="selected" href="page2.html"> Avanc√©es </a>
		<a href="page3.html"> Autres Applications </a>
	</div>
</nav>

<!-- Article -->
<main>
	<br/>
	<div class="content">
		<h1>L'histoire du Machine Learning</h1>
		<br/><br/>

		<br>
		<br>
		<br>

		<h2>Table des mati√®res</h2>
		<div class="sommaire-links">
			<a class="sommaire" href="#d√©but">- Les d√©buts du Machine Learning</a><br> 		
			<a class="sommaire" href="#√©volution">- L'√©volution qu'il subit au cours des ann√©es</a><br>
			<a class="sommaire" href="#historique">- Tableau de l'historique du Machine Learning</a><br>
			<a class="sommaire" href="#exemple">- Un exemple de Machine Learning : LipNet</a><br>
		</div>
		

		<br>
		<br>
		<br>
		
		<h3 id="d√©but">üîó Les d√©buts du Machine Learning</h3>
		<br/><br/>

		<p>	Une avanc√©e majeure dans le secteur de l'intelligence machine est le succ√®s de l'ordinateur d√©velopp√© par IBM, Deep Blue, qui est le premier √† vaincre le champion mondial d'√©checs Garry Kasparov en 1997. Le projet Deep Blue en inspirera nombre d'autres dans le cadre de l'intelligence artificielle, particuli√®rement un autre grand d√©fi : IBM Watson, l'ordinateur dont le but est de gagner au jeu Jeopardy!. Ce but est atteint en 2011, quand Watson gagne √† Jeopardy! en r√©pondant aux questions par traitement de langage naturel</p>

		<br>
		<br>

		<h3 id="√©volution">üîó L'√©volution qu'il subit au cours des ann√©es</h3>
		<br/><br/>

		<p>	Durant les ann√©es suivantes, les applications de l'apprentissage automatique m√©diatis√©es se succ√®dent bien plus rapidement qu'auparavant.</p>

		<br>
		<br> 

		<p>	En 2012, un r√©seau neuronal d√©velopp√© par Google parvient √† reconna√Ætre des visages humains ainsi que des chats dans des vid√©os YouTube.</p>	

		<br>

		<p>En 2014, 64 ans apr√®s la pr√©diction d'Alan Turing, le dialogueur Eugene Goostman (Il s‚Äôagit d‚Äôune intelligence artificielle russe cr√©√©e en 2001 qui est un agent conversationnel) est le premier √† r√©ussir le test de Turing en parvenant √† convaincre 33 % des juges humains au bout de cinq minutes de conversation qu'il est non pas un ordinateur, mais un gar√ßon ukrainien de 13 ans. </p>

		<p>En 2015, une nouvelle √©tape importante est atteinte lorsque l'ordinateur ¬´ AlphaGo ¬ª de Google gagne contre un des meilleurs joueurs au jeu de Go, jeu de plateau consid√©r√© comme le plus dur du monde.</p>

		<br>
		<br>

		<h3 id="historique">üîó Tableau de l'historique du Machine Learning</h3>
		<br>

		<table class="tableHistory">
			<tr>
				<th>D√©cennie</th>
				<th>R√©summ√©</th>
			</tr>
			<tr>
				<td>Avant 1950</td>
				<td>Des m√©thodes statistiques sont d√©couvertes et affin√©es.</td>
			</tr>
			<tr>
				<td>1950</td>
				<td>La recherche pionni√®re en Machine Learning est men√©e √† l'aide d'algorithmes simples.</td>
			</tr>
			<tr>
				<td>1960</td>
				<td>Les m√©thodes bay√©siennes sont introduites pour l' inf√©rence probabiliste dans l'apprentissage automatique.</td>
			</tr>
			<tr>
				<td>1970</td>
				<td>¬´ AI Winter ¬ª caus√© par le pessimisme quant √† l'efficacit√© de l'apprentissage automatique.</td>
			</tr>
			<tr>
				<td>1980</td>
				<td>La red√©couverte de la r√©tropropagation provoque une r√©surgence de la recherche sur l'apprentissage automatique.</td>
			</tr>
			<tr>
				<td>1990</td>
				<td>Le travail sur le Marchine Learning passe d'une approche ax√©e sur les connaissances √† une approche ax√©e sur les donn√©es. Les scientifiques commencent √† cr√©er des programmes informatiques pour analyser de grandes quantit√©s de donn√©es et tirer des conclusions - ou ¬´apprendre¬ª - √† partir des r√©sultats. Les machines vectorielles de soutien (SVM) et les r√©seaux neuronaux r√©currents (RNN) deviennent populaires. Les domaines de la complexit√© informatique via les r√©seaux de neurones et le calcul super-Turing ont commenc√©.</td>
			</tr>
			<tr>
				<td>2000</td>
				<td>Le support Vector Clustering et d'autres m√©thodes de noyau et les m√©thodes d'apprentissage automatique non supervis√©es se r√©pandent.</td>
			</tr>
			<tr>
				<td>2010</td>
				<td>Le Deep Learning devient possible, ce qui conduit l'apprentissage automatique √† devenir partie int√©grante de nombreux services et applications logiciels largement utilis√©s.</td>
			</tr>
		</table>
		<a class="sources" href="https://en.wikipedia.org/wiki/Timeline_of_machine_learning" target="_blank">Sources: wikipedia</a>


		<br>
		<br>

		<h3 id="exemple">üîó Un exemple de Machine Learning : LipNet</h3>
		<br/><br/>

		<p>En 2016, un syst√®me d'intelligence artificielle √† base d'apprentissage automatique nomm√© LipNet parvient √† lire sur les l√®vres avec un grand taux de succ√®s.</p>

		<br>

		<p>Au d√©part, il s'agissait de d√©velopper une intelligence artificielle capable de traduire automatiquement un texte ou simuler une voix presque humaine. D√©sormais, cette IA est donc capable de lire sur les l√®vres (sans source sonore donc), r√©v√®le New Scientist. Le programme baptis√© LipNet peut ainsi convertir les mouvements de l√®vres en texte et s'en sort mieux qu'un sp√©cialiste humain de la question. L'application obtient en effet un score de 47% de reconnaissance exacte contre 24% pour l'humain.</p>

		<br>

		<p>Voici une vid√©o qui montre la fa√ßon dont LipNet r√©ussit √† lire sur les l√®vres : </p>

		<br>

		<div class="videoWrapper">
			<iframe class="video" src="https://www.youtube.com/embed/fa5QGremQf8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
		</div>
		<p class="sources-simple">Source: Lipnet - Yannis Assael</p>

		<br>

		<br>
					
	</div>

</main>

<!-- Footer -->
<footer>
	<div class="footer_center">
		
		<p>Projet M1105 PPP Toulouse <span class="footer_lightText">- 2020-2021</span></p>

		<br>
		<hr class="separator">
		<br>

		<table>
			<tr>
				<td>Pierre Lacoste</td>
				<td>Nathan Ruiz</td>
				<td>D√©wi Girot</td>
			</tr>
			<tr>
				<td>Salih Madhi</td>
				<td>L√©o Deschaux-Beaume</td>
			</tr>
		</table>

		<br>
		<hr class="separator">
		<br>

		<a class="sources" href="https://github.com/Pierll/M1105.git">Projet Git</a>
		
	</div>

	<img src="img/logoIUT.png" alt="logo IUT PAUL SABATIER" class="footer_logo"/>
</footer>

</body>
</html>